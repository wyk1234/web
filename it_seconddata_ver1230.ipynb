{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(rf\"/home/a/Lwy_research\")\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这一部分函数之前有\n",
    "# 计算完整的秒序列\n",
    "def calc_sec_list(keep_last = False):\n",
    "    time_series=[]  #所有的秒序列,不包括早尾盘集合竞价(也就是093000-145659的)\n",
    "    for i in [9,10,11,13,14]:\n",
    "        for j in range(60):\n",
    "            if i==9 and j<30:\n",
    "                continue\n",
    "            elif i==11 and j>=30:\n",
    "                continue\n",
    "            elif i==14 and j>=57:\n",
    "                continue\n",
    "            time_series.extend([int(str(i)+'0'*(2-len(str(j)))+str(j)+'0'*(2-len(str(x)))+str(x)) for x in range(60)])\n",
    "    if keep_last: # 保留最后一个时点\n",
    "        time_series += [150000]\n",
    "    return time_series\n",
    "\n",
    "# 转化为1秒级时间,比如如果time为93524380，且转化的1s时间为93524000\n",
    "def get_second_1s(time_10ms):\n",
    "    div = 1000\n",
    "    return round(round(time_10ms // div) * div) # 先取整再标准化为Level2时间\n",
    "\n",
    "# 转化为分钟时间,比如如果time为93524380，且转化的1s时间为93500000\n",
    "def get_second_60s(time_10ms):\n",
    "    div = 100000\n",
    "    return round(round(time_10ms // div) * div) # 先取整再标准化为Level2时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对一些基本的逐笔成交、逐笔委托数据进行计算\n",
    "def calc_stock_second_data_basic(code, trans_data, order_data,  intra_support_data, standard_time_list, get_second_map):\n",
    "    '''\n",
    "    使用逐笔成交和逐笔委托构成的合成数据，包含一些统计量，如过去几秒的订单量、价格等\n",
    "    要求尽可能使用流式计算，加快速度，如均值、标准差等统计量都可以一笔订单一笔订单计算\n",
    "    '''\n",
    "# try:\n",
    "    def _process_second_data0(code, second_data0, standard_time_list, intra_support_data):\n",
    "        second_data0 = second_data0.reindex(standard_time_list)\n",
    "        second_data = pd.DataFrame().reindex_like(second_data0)\n",
    "        pre_close = intra_support_data.loc[code, 'preclose']\n",
    "        preprocess_dict = {\n",
    "            1: ['OrderPriceMean_B','OrderPriceStd_B','OrderPriceMean_S','OrderPriceStd_S',\n",
    "                'TradePriceMean_B','TradePriceStd_B','TradePriceMean_S','TradePriceStd_S',\n",
    "                'Open','High','Low','Close', \n",
    "                'OrderAmtSum_B','OrderAmtMax_B','OrderAmtbig_B','OrderAmtmid_B','OrderAmtsma_B',\n",
    "                'OrderAmtSum_S','OrderAmtMax_S','OrderAmtbig_S','OrderAmtmid_S','OrderAmtsma_S',\n",
    "                'TradeAmtSum_B','TradeAmtMax_B','TradeAmtbig_B','TradeAmtmid_B','TradeAmtsma_B',\n",
    "                'TradeAmtSum_S','TradeAmtMax_S','TradeAmtbig_S','TradeAmtmid_S','TradeAmtsma_S',\n",
    "                \"CancelAmtSum_B\", \"CancelAmtMax_B\", \"CancelAmtSum_S\", \"CancelAmtMax_S\",\n",
    "                ],\n",
    "            2: ['OrderVolSum_B','OrderVolMax_B','OrderVolbig_B','OrderVolmid_B','OrderVolsma_B','OrderVolSquareSum_B',\n",
    "                'OrderVolSum_S','OrderVolMax_S','OrderVolbig_S','OrderVolmid_S','OrderVolsma_S','OrderVolSquareSum_S',\n",
    "                'CancelVolSum_B','CancelVolMax_B','CancelVolSquareSum_B','CancelVolSumJg_B','CancelVolSumPart_B',\n",
    "                'CancelVolSum_S','CancelVolMax_S','CancelVolSquareSum_S','CancelVolSumJg_S','CancelVolSumPart_S',\n",
    "                'TradeVolSum_B','TradeVolMax_B','TradeVolbig_B','TradeVolmid_B','TradeVolsma_B','TradeVolSquareSum_B',\n",
    "                'TradeVolSum_S','TradeVolMax_S','TradeVolbig_S','TradeVolmid_S','TradeVolsma_S','TradeVolSquareSum_S',\n",
    "                'OrderNumSum_B','OrderNumSum_S','CancelNumSum_B','CancelNumSum_S','TradeNumSum_B','TradeNumSum_S'\n",
    "                ],\n",
    "        }\n",
    "        \n",
    "        for field in second_data0.columns:\n",
    "            df = second_data0[field]\n",
    "            # 对基础数据进行标准化，价格和成交金额相关的除以preclose，成交额和笔数相关的不用\n",
    "            if field in preprocess_dict[1]:\n",
    "                df = df / pre_close\n",
    "            elif field in preprocess_dict[2]:\n",
    "                df = df\n",
    "            else:\n",
    "                raise ValueError(f\"Field not in preprocess_dict: {field}\")\n",
    "            \n",
    "            if (field in [\"Open\", \"High\", \"Low\", \"Close\"]) : # 价格填充\n",
    "                df = df.replace(0,np.nan).ffill().fillna(1.0)\n",
    "            elif ('Price' in field): # 涉及到价格数据，统一不进行填充，保留nan\n",
    "                pass\n",
    "            else: # 量额填充\n",
    "                df = df.fillna(0.0)\n",
    "            second_data[field] = df\n",
    "        return second_data\n",
    "    \n",
    "    temp_list = [] # 将所有的初步结果拼接起来的列表\n",
    "    # 逐笔成交数据处理\n",
    "    trans_data[\"second\"] = trans_data[\"time\"].map(get_second_map)\n",
    "    trans_data['transVolSquare']=trans_data['transVolume']**2/10000\n",
    "    \n",
    "    # 成交订单在计算大小单阈值时不区分B、S\n",
    "    # 计算早盘成交金额数据，用来衡量大中小单, 意味着10点之前衡量每笔订单大小的阈值会不一样，10点之后订单的判断阈值统一按照10点的组来定\n",
    "    trans_data[\"tradeAmtMean\"] = trans_data.rolling(len(trans_data), min_periods = 1)[\"transAmount\"].mean().values\n",
    "    if len(trans_data) == 1:\n",
    "        trans_data[\"tradeAmtStd\"] = 0\n",
    "    else:\n",
    "        trans_data[\"tradeAmtStd\"] = trans_data.rolling(len(trans_data), min_periods = 2)[\"transAmount\"].std().values\n",
    "    trans_data.loc[trans_data[\"time\"] >= normalize_time(\"1000\"), [\"tradeAmtMean\", \"tradeAmtStd\"]] = np.nan\n",
    "    trans_data[[\"tradeAmtMean\", \"tradeAmtStd\"]] = trans_data[[\"tradeAmtMean\", \"tradeAmtStd\"]].ffill()\n",
    "    trans_data[\"AmtType\"] = \"mid\"\n",
    "    trans_data.loc[trans_data[\"transAmount\"] <= trans_data[\"tradeAmtMean\"], \"AmtType\"] = \"sma\"\n",
    "    trans_data.loc[trans_data[\"transAmount\"] >= (trans_data[\"tradeAmtMean\"] +  trans_data[\"tradeAmtStd\"]), \"AmtType\"] = \"big\" \n",
    "    \n",
    "    # 再处理成交部分，分买卖\n",
    "    for side in [\"B\", \"S\"]:\n",
    "        data = trans_data[trans_data[\"transSide\"]==side]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        #计算一些统计量指标\n",
    "        data_group = data.groupby([\"second\"])\n",
    "        temp1 = data_group.agg({\"transPrice\": [\"count\", \"mean\", \"std\"],\n",
    "                                \"transVolume\": [\"sum\", \"max\"],\n",
    "                                \"transAmount\": [\"sum\", \"max\"],\n",
    "                                \"transVolSquare\": [\"sum\"]})\n",
    "        \n",
    "        temp1.columns = [\"TradeNumSum\",\"TradePriceMean\" ,\"TradePriceStd\", \"TradeVolSum\", \"TradeVolMax\", \"TradeAmtSum\", \"TradeAmtMax\",'TradeVolSquareSum']    \n",
    "        temp2 = data.groupby([\"second\", \"AmtType\"])[\"transAmount\"].sum().unstack()\n",
    "        temp2.columns = [\"TradeAmt\" + x  for x in temp2.columns]\n",
    "        temp3 = data.groupby([\"second\", \"AmtType\"])[\"transVolume\"].sum().unstack()\n",
    "        temp3.columns = [\"TradeVol\" + x  for x in temp3.columns]\n",
    "        temp = pd.concat([temp1, temp2, temp3], axis=1)\n",
    "        temp.columns = [col+\"_%s\" % side for col in temp.columns]\n",
    "        temp_list.append(temp)\n",
    "\n",
    "    # 最后计算每个second开高低收价格\n",
    "    data = trans_data.copy()\n",
    "    temp = data.groupby([\"second\"]).agg({\"transPrice\": [\"first\", \"max\", \"min\", \"last\"]})\n",
    "    temp.columns = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "    temp_list.append(temp)\n",
    "\n",
    "    # 逐笔委托和撤单数据处理\n",
    "    order_data[\"second\"] = order_data[\"time\"].map(get_second_map)\n",
    "    # 1457之后的委托归属150000000的second\n",
    "    order_data.loc[order_data.second >= 145700000, \"second\"] = 150000000\n",
    "    \n",
    "    # 在计算基础字段时，撤单和委托数据的成交量、金额都取成正的\n",
    "    order_data[[\"orderVolume\", \"orderAmount\"]] = np.abs(order_data[[\"orderVolume\", \"orderAmount\"]])\n",
    "    \n",
    "    order_data['orderVolSquare']=order_data['orderVolume']**2/10000\n",
    "    cancel_data = order_data[order_data[\"orderType\"].isin(['C','D'])] # 撤单数据\n",
    "    order_data = order_data[~order_data[\"orderType\"].isin(['C','D'])] # 委托数据\n",
    "    \n",
    "    \n",
    "    # 计算一笔订单撤单时间和原始委托时间差\n",
    "    cancel_data = cancel_data.merge(order_data[['orderIdOrigin','time','orderVolume']],on=['orderIdOrigin'],how='left')\n",
    "    cancel_data=cancel_data.rename(columns={'time_x':'time',\n",
    "                                            'orderVolume_x':'orderVolume'})\n",
    "    cancel_data['interval']=(pd.to_datetime(cancel_data['time'],format='%H%M%S%f')- \\\n",
    "                                pd.to_datetime(cancel_data['time_y'],format='%H%M%S%f')).dt.seconds\n",
    "\n",
    "    #撤单数据目前保存在委托数据中\n",
    "    for side in [\"B\", \"S\"]:\n",
    "        data = cancel_data[cancel_data[\"orderSide\"]==side]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "\n",
    "        data_group = data.groupby([\"second\"])\n",
    "        temp1 = data_group.agg({\"orderVolume\": [\"count\", \"sum\", \"max\"],\n",
    "                                \"orderAmount\": [\"sum\", \"max\"],\n",
    "                                \"orderVolSquare\":[\"sum\"]})\n",
    "        temp1.columns = [\"CancelNumSum\", \"CancelVolSum\", \"CancelVolMax\",\"CancelAmtSum\", \"CancelAmtMax\", \"CancelVolSquareSum\"]\n",
    "        \n",
    "        data1 = data[data['interval']<15]  #撤单时间小于15s\n",
    "        temp2 = data1.groupby([\"second\"]).agg({\"orderVolume\": [\"sum\"]})\n",
    "        temp2.columns= ['CancelVolSumJg']\n",
    "        \n",
    "        data2=data[-data['orderVolume']+data['orderVolume_y']>0]  #撤单量小于委托量的\n",
    "        temp3=data2.groupby([\"second\"]).agg({\"orderVolume\": [\"sum\"]})\n",
    "        temp3.columns= ['CancelVolSumPart']\n",
    "        \n",
    "        temp=pd.concat([temp1, temp2, temp3], axis=1)\n",
    "        temp.columns = [col+\"_%s\" % side for col in temp.columns]\n",
    "        temp_list.append(temp)\n",
    "\n",
    "    order_data  = order_data.sort_values([\"time\", \"orderId\"]).reset_index(drop = True)\n",
    "    for side in [\"B\", \"S\"]:\n",
    "        data = order_data[order_data[\"orderSide\"]==side]\n",
    "        data2 = data.loc[data[\"orderType\"].isin(['1','A'])] # 仅含限价单\n",
    "        if len(data2) == 0:\n",
    "            continue\n",
    "        # 计算早盘成交金额数据，用来衡量大中小单, 意味着10点之前衡量每笔订单大小的阈值会不一样，10点之后订单的判断阈值统一按照10点的组来定\n",
    "        data2[\"orderAmtMean\"] = data2.rolling(len(data2), min_periods = 1)[\"orderAmount\"].mean().values\n",
    "        if len(data2) == 1:\n",
    "            data2[\"orderAmtStd\"] = 0\n",
    "        else:\n",
    "            data2[\"orderAmtStd\"] = data2.rolling(len(data2), min_periods = 2)[\"orderAmount\"].std().values\n",
    "        data2.loc[data2[\"time\"] >= normalize_time(\"1000\"), [\"orderAmtMean\", \"orderAmtStd\"]] = np.nan\n",
    "        data2[[\"orderAmtMean\", \"orderAmtStd\"]] = data2[[\"orderAmtMean\", \"orderAmtStd\"]].ffill()\n",
    "        \n",
    "        data2[\"AmtType\"] = \"mid\"\n",
    "        data2.loc[data2[\"orderAmount\"] <= data2[\"orderAmtMean\"], \"AmtType\"] = \"sma\"\n",
    "        data2.loc[data2[\"orderAmount\"] >= (data2[\"orderAmtMean\"] +  data2[\"orderAmtStd\"]), \"AmtType\"] = \"big\" \n",
    "        \n",
    "        temp1 = data2.groupby([\"second\"]).agg({\"orderPrice\": [\"count\", \"mean\", \"std\"],\n",
    "                                \"orderVolume\": [\"sum\", \"max\"],\n",
    "                                \"orderAmount\": [\"sum\", \"max\"],\n",
    "                                \"orderVolSquare\": [\"sum\"]})\n",
    "        temp1.columns = [\"OrderNumSum\", \"OrderPriceMean\",\"OrderPriceStd\", \"OrderVolSum\", \"OrderVolMax\",\"OrderAmtSum\", \"OrderAmtMax\",\"OrderVolSquareSum\"]\n",
    "        temp2 = data2.groupby([\"second\", \"AmtType\"])[\"orderAmount\"].sum().unstack()\n",
    "        temp2.columns = [\"OrderAmt\" + x  for x in temp2.columns]\n",
    "        temp3 = data2.groupby([\"second\", \"AmtType\"])[\"orderVolume\"].sum().unstack()\n",
    "        temp3.columns = [\"OrderVol\" + x  for x in temp3.columns]\n",
    "        temp = pd.concat([temp1, temp2, temp3], axis=1)\n",
    "        temp.columns = [col+\"_%s\" % side for col in temp.columns]\n",
    "        temp_list.append(temp)\n",
    "\n",
    "\n",
    "    # 进一步处理秒级数据\n",
    "    second_data0 = pd.concat(temp_list, axis=1)\n",
    "    second_data = _process_second_data0(code, second_data0, standard_time_list, intra_support_data)\n",
    "    second_data[\"Code\"] = code\n",
    "    second_data = second_data.reset_index().set_index(\"Code\")\n",
    "    return second_data\n",
    "# except Exception as e:\n",
    "#     print(code,e)\n",
    "#     return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14221/14221 [00:00<00:00, 1089904.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step = \"60s\" # 这里time_step有可能是1s、5s、10s、60s，这里用60s只作为示例和核对作用\n",
    "get_second_map = eval(rf\"get_second_{time_step}\")\n",
    "second_list = calc_sec_list(keep_last=True)\n",
    "second_list = [x*1000 for x in second_list]\n",
    "standard_time_list = []\n",
    "for time in tqdm(second_list):\n",
    "    if get_second_map(time) not in standard_time_list:\n",
    "        standard_time_list.append(get_second_map(time))\n",
    "len(standard_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 56.26it/s]\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 120.48it/s]\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 121.38it/s]\n",
      "100%|██████████| 1000/1000 [00:07<00:00, 125.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for date in get_trade_days(\"20240910\", \"20240913\"):\n",
    "    sample_order_data = pd.read_feather(rf\"./example_data/sample_order_{date}.fea\")\n",
    "    sample_trans_data = pd.read_feather(rf\"./example_data/sample_trans_{date}.fea\")\n",
    "    order_data_dict = change_df2dict(sample_order_data)\n",
    "    trans_data_dict = change_df2dict(sample_trans_data)\n",
    "    intra_support_data = pd.read_csv(rf\"./example_data/stock_intra_support_{date}.csv\", index_col=\"Code\")\n",
    "    intra_support_data.index = ['%06d'%int(x) for x in intra_support_data.index]\n",
    "\n",
    "    code_list = set(order_data_dict.keys()) & set(order_data_dict.keys())\n",
    "\n",
    "    # for code in tqdm(code_list):\n",
    "    #     order_data = order_data_dict[code]\n",
    "    #     trans_data = trans_data_dict[code]\n",
    "    #     second_data = calc_stock_second_data(code, trans_data, order_data,  intra_support_data, standard_time_list, get_second_map)\n",
    "\n",
    "    second_data_list = Parallel(n_jobs=32)(delayed(calc_stock_second_data_basic)(code, trans_data_dict[code], order_data_dict[code],  intra_support_data, standard_time_list, get_second_map) for code in tqdm(code_list))\n",
    "    pd.concat(second_data_list).reset_index().to_feather(rf\"./example_data/sample_second_{date}.fea\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
